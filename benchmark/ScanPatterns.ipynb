{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import math\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import collections\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import Bio.ExPASy.Prosite as BEP\n",
    "import praline\n",
    "import praline.container\n",
    "import mapraline.component\n",
    "import mapraline.prosite\n",
    "from praline.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'RV100/'\n",
    "TRACK_ID_BASE = \"mapraline.track.PrositePatternAnnotation\"\n",
    "FMT_TRACK_ID = \"{0}_{1}\"\n",
    "ALPHABET = mapraline.ALPHABET_PROSITE\n",
    "PROSITE_PATH = '/Users/maurits/Downloads/prosite.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patterns(path):\n",
    "    patterns = []\n",
    "\n",
    "    with file(path, 'r') as fi:\n",
    "        for record in BEP.parse(fi):\n",
    "            pattern = record.pattern.rstrip('.')\n",
    "            if len(pattern):\n",
    "                patterns.append(pattern)\n",
    "    \n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "# Read all patterns from our local prosite db.\n",
    "patterns = read_patterns(PROSITE_PATH)\n",
    "\n",
    "seq_sets = []\n",
    "for path, dirnames, filenames in os.walk(INPUT_DIR):\n",
    "    for filename in filenames:\n",
    "        if not filename.endswith('.tfa'):\n",
    "            continue\n",
    "            \n",
    "        path = os.path.join(INPUT_DIR, filename)\n",
    "        try:\n",
    "            seq_set = praline.load_sequence_fasta(path, praline.container.ALPHABET_AA)\n",
    "        except praline.AlphabetError:\n",
    "            continue\n",
    "        \n",
    "        seq_sets.append((filename, seq_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "seq_sets = [(f, s) for f, s in seq_sets if len(s) < 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_names = [os.path.splitext(f)[0] for f, s in seq_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexes = []\n",
    "for pattern in patterns:\n",
    "    re = mapraline.prosite.pattern_to_re(pattern)\n",
    "    regexes.append((pattern, re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_sequences(seqs):\n",
    "    raw_seqs = []\n",
    "    for seq in seqs:\n",
    "        track = seq.get_track(praline.container.TRACK_ID_INPUT)\n",
    "        \n",
    "        indices = track.values\n",
    "        sym_list = []\n",
    "        for n in xrange(indices.shape[0]):\n",
    "            sym_list.append(track.alphabet.index_to_symbol(indices[n]))\n",
    "        raw_seqs.append(\"\".join(sym_list))\n",
    "    \n",
    "    return raw_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_seq_sets = [get_raw_sequences(seq_set) for filename, seq_set in seq_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_to_match_sets = {}\n",
    "for pattern, regex in regexes:\n",
    "    match_sets = []\n",
    "    for seq_set in raw_seq_sets:\n",
    "        match_set = []\n",
    "        for seq in seq_set:\n",
    "            matches = list(regex.finditer(seq, overlapped=True))\n",
    "            match_set.append(matches)\n",
    "        match_sets.append(match_set)\n",
    "    pattern_to_match_sets[pattern] = match_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_set = collections.defaultdict(lambda: 0)\n",
    "count_per_seq = collections.defaultdict(lambda: 0)\n",
    "for pattern, match_sets in pattern_to_match_sets.iteritems():\n",
    "    for i, match_set in enumerate(match_sets):\n",
    "        for j, matches in enumerate(match_set):\n",
    "            count_per_set[i] += len(matches)\n",
    "            count_per_seq[i, j] += len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array(count_per_set.values())\n",
    "lengths = np.array([sum(len(seq) for seq in set_) for set_ in raw_seq_sets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_counts = counts / lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.030540179423554113, 0.0942772080714522, 0.052956166529453924)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_counts.min(), normalized_counts.max(), normalized_counts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 105, 0.052956166529453924)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_counts.argmin(), normalized_counts.argmax(), normalized_counts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_to_covered = {}\n",
    "for pattern, match_sets in pattern_to_match_sets.iteritems():\n",
    "    covered_sets = []\n",
    "    for i, match_set in enumerate(match_sets):\n",
    "        num_covered = 0\n",
    "        for matches in match_set:\n",
    "            if len(matches) > 0:\n",
    "                num_covered += 1\n",
    "        if (num_covered / len(match_set)) > 0.5:\n",
    "            covered_sets.append(i)\n",
    "    \n",
    "    if len(covered_sets) > 0:\n",
    "        pattern_to_covered[pattern] = covered_sets\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "covered_by = collections.defaultdict(set)\n",
    "for pattern, families in pattern_to_covered.iteritems():\n",
    "    for family in families:\n",
    "        covered_by[family_names[family]].add(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./commands.txt', 'w') as fo:\n",
    "    for alpha in [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 100]:\n",
    "        for family, patterns in covered_by.iteritems():\n",
    "            filename = \"{}.tfa\".format(family)\n",
    "            fmt = \"mapraline input/{0} output/{1} --motif-match-score {2} {3}\"\n",
    "            pat_str = \" \".join(\"-p '{0}'\".format(x) for x in patterns)\n",
    "\n",
    "            base_fname, ext = os.path.splitext(filename)\n",
    "            out_filename = '{0}_alpha_{1}.aln'.format(base_fname, alpha)\n",
    "            print >>fo, fmt.format(filename, out_filename, alpha, pat_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./s3_table.csv', 'wb') as fo:\n",
    "    writer = csv.DictWriter(fo, dialect='excel', fieldnames=['BB4_family', 'pattern'])\n",
    "    writer.writeheader()\n",
    "    for family, patterns in sorted(covered_by.items(), key=lambda x: int(x[0][4:])):\n",
    "        pat_list = list(patterns)\n",
    "        writer.writerow({'BB4_family': family, 'pattern': pat_list[0]})\n",
    "        for pattern in pat_list[1:]:\n",
    "            writer.writerow({'BB4_family': '', 'pattern': pattern})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./family_patterns.pickle', 'wb') as fo:\n",
    "    pickle.dump(covered_by, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
